# Stubs for tensorflow.contrib.layers.python.layers.layers (Python 3)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

from tensorflow.contrib.framework.python.ops import add_arg_scope as add_arg_scope, variables as variables
from tensorflow.contrib.layers.python.layers import initializers as initializers, utils as utils
from tensorflow.python.eager import context as context
from tensorflow.python.framework import constant_op as constant_op, dtypes as dtypes, function as function, ops as ops, sparse_tensor as sparse_tensor, tensor_shape as tensor_shape
from tensorflow.python.layers import base as base
from tensorflow.python.ops import array_ops as array_ops, check_ops as check_ops, init_ops as init_ops, linalg_ops as linalg_ops, math_ops as math_ops, nn as nn, sparse_ops as sparse_ops, standard_ops as standard_ops, variable_scope as variable_scope
from tensorflow.python.training import moving_averages as moving_averages
from typing import Any as Any, Optional as Optional

def avg_pool2d(inputs: Any, kernel_size: Any, stride: int = ..., padding: str = ..., data_format: Any = ..., outputs_collections: Optional[Any] = ..., scope: Optional[Any] = ...): ...
def avg_pool3d(inputs: Any, kernel_size: Any, stride: int = ..., padding: str = ..., data_format: Any = ..., outputs_collections: Optional[Any] = ..., scope: Optional[Any] = ...): ...
def batch_norm(inputs: Any, decay: float = ..., center: bool = ..., scale: bool = ..., epsilon: float = ..., activation_fn: Optional[Any] = ..., param_initializers: Optional[Any] = ..., param_regularizers: Optional[Any] = ..., updates_collections: Any = ..., is_training: bool = ..., reuse: Optional[Any] = ..., variables_collections: Optional[Any] = ..., outputs_collections: Optional[Any] = ..., trainable: bool = ..., batch_weights: Optional[Any] = ..., fused: Optional[Any] = ..., data_format: Any = ..., zero_debias_moving_mean: bool = ..., scope: Optional[Any] = ..., renorm: bool = ..., renorm_clipping: Optional[Any] = ..., renorm_decay: float = ..., adjustment: Optional[Any] = ...): ...
def bias_add(inputs: Any, activation_fn: Optional[Any] = ..., initializer: Any = ..., regularizer: Optional[Any] = ..., reuse: Optional[Any] = ..., variables_collections: Optional[Any] = ..., outputs_collections: Optional[Any] = ..., trainable: bool = ..., data_format: Any = ..., scope: Optional[Any] = ...): ...
def convolution(inputs: Any, num_outputs: Any, kernel_size: Any, stride: int = ..., padding: str = ..., data_format: Optional[Any] = ..., rate: int = ..., activation_fn: Any = ..., normalizer_fn: Optional[Any] = ..., normalizer_params: Optional[Any] = ..., weights_initializer: Any = ..., weights_regularizer: Optional[Any] = ..., biases_initializer: Any = ..., biases_regularizer: Optional[Any] = ..., reuse: Optional[Any] = ..., variables_collections: Optional[Any] = ..., outputs_collections: Optional[Any] = ..., trainable: bool = ..., scope: Optional[Any] = ..., conv_dims: Optional[Any] = ...): ...
def convolution1d(inputs: Any, num_outputs: Any, kernel_size: Any, stride: int = ..., padding: str = ..., data_format: Optional[Any] = ..., rate: int = ..., activation_fn: Any = ..., normalizer_fn: Optional[Any] = ..., normalizer_params: Optional[Any] = ..., weights_initializer: Any = ..., weights_regularizer: Optional[Any] = ..., biases_initializer: Any = ..., biases_regularizer: Optional[Any] = ..., reuse: Optional[Any] = ..., variables_collections: Optional[Any] = ..., outputs_collections: Optional[Any] = ..., trainable: bool = ..., scope: Optional[Any] = ...): ...
def convolution2d(inputs: Any, num_outputs: Any, kernel_size: Any, stride: int = ..., padding: str = ..., data_format: Optional[Any] = ..., rate: int = ..., activation_fn: Any = ..., normalizer_fn: Optional[Any] = ..., normalizer_params: Optional[Any] = ..., weights_initializer: Any = ..., weights_regularizer: Optional[Any] = ..., biases_initializer: Any = ..., biases_regularizer: Optional[Any] = ..., reuse: Optional[Any] = ..., variables_collections: Optional[Any] = ..., outputs_collections: Optional[Any] = ..., trainable: bool = ..., scope: Optional[Any] = ...): ...
def convolution3d(inputs: Any, num_outputs: Any, kernel_size: Any, stride: int = ..., padding: str = ..., data_format: Optional[Any] = ..., rate: int = ..., activation_fn: Any = ..., normalizer_fn: Optional[Any] = ..., normalizer_params: Optional[Any] = ..., weights_initializer: Any = ..., weights_regularizer: Optional[Any] = ..., biases_initializer: Any = ..., biases_regularizer: Optional[Any] = ..., reuse: Optional[Any] = ..., variables_collections: Optional[Any] = ..., outputs_collections: Optional[Any] = ..., trainable: bool = ..., scope: Optional[Any] = ...): ...
def convolution2d_in_plane(inputs: Any, kernel_size: Any, stride: int = ..., padding: str = ..., activation_fn: Any = ..., normalizer_fn: Optional[Any] = ..., normalizer_params: Optional[Any] = ..., weights_initializer: Any = ..., weights_regularizer: Optional[Any] = ..., biases_initializer: Any = ..., biases_regularizer: Optional[Any] = ..., reuse: Optional[Any] = ..., variables_collections: Optional[Any] = ..., outputs_collections: Optional[Any] = ..., trainable: bool = ..., scope: Optional[Any] = ...): ...
def convolution2d_transpose(inputs: Any, num_outputs: Any, kernel_size: Any, stride: int = ..., padding: str = ..., data_format: Any = ..., activation_fn: Any = ..., normalizer_fn: Optional[Any] = ..., normalizer_params: Optional[Any] = ..., weights_initializer: Any = ..., weights_regularizer: Optional[Any] = ..., biases_initializer: Any = ..., biases_regularizer: Optional[Any] = ..., reuse: Optional[Any] = ..., variables_collections: Optional[Any] = ..., outputs_collections: Optional[Any] = ..., trainable: bool = ..., scope: Optional[Any] = ...): ...
def convolution3d_transpose(inputs: Any, num_outputs: Any, kernel_size: Any, stride: int = ..., padding: str = ..., data_format: Any = ..., activation_fn: Any = ..., normalizer_fn: Optional[Any] = ..., normalizer_params: Optional[Any] = ..., weights_initializer: Any = ..., weights_regularizer: Optional[Any] = ..., biases_initializer: Any = ..., biases_regularizer: Optional[Any] = ..., reuse: Optional[Any] = ..., variables_collections: Optional[Any] = ..., outputs_collections: Optional[Any] = ..., trainable: bool = ..., scope: Optional[Any] = ...): ...
def dense_to_sparse(tensor: Any, eos_token: int = ..., outputs_collections: Optional[Any] = ..., scope: Optional[Any] = ...): ...
def dropout(inputs: Any, keep_prob: float = ..., noise_shape: Optional[Any] = ..., is_training: bool = ..., outputs_collections: Optional[Any] = ..., scope: Optional[Any] = ..., seed: Optional[Any] = ...): ...
def flatten(inputs: Any, outputs_collections: Optional[Any] = ..., scope: Optional[Any] = ...): ...
def fully_connected(inputs: Any, num_outputs: Any, activation_fn: Any = ..., normalizer_fn: Optional[Any] = ..., normalizer_params: Optional[Any] = ..., weights_initializer: Any = ..., weights_regularizer: Optional[Any] = ..., biases_initializer: Any = ..., biases_regularizer: Optional[Any] = ..., reuse: Optional[Any] = ..., variables_collections: Optional[Any] = ..., outputs_collections: Optional[Any] = ..., trainable: bool = ..., scope: Optional[Any] = ...): ...

class GDN(base.Layer):
    inverse: Any = ...
    data_format: Any = ...
    input_spec: Any = ...
    def __init__(self, inverse: bool = ..., beta_min: float = ..., gamma_init: float = ..., reparam_offset: Any = ..., data_format: str = ..., activity_regularizer: Optional[Any] = ..., trainable: bool = ..., name: Optional[Any] = ..., **kwargs: Any) -> None: ...
    beta: Any = ...
    gamma: Any = ...
    built: bool = ...
    def build(self, input_shape: Any): ...
    def call(self, inputs: Any): ...
    def compute_output_shape(self, input_shape: Any): ...

def gdn(inputs: Any, inverse: bool = ..., beta_min: float = ..., gamma_init: float = ..., reparam_offset: Any = ..., data_format: str = ..., activity_regularizer: Optional[Any] = ..., trainable: bool = ..., name: Optional[Any] = ..., reuse: Optional[Any] = ...): ...
def layer_norm(inputs: Any, center: bool = ..., scale: bool = ..., activation_fn: Optional[Any] = ..., reuse: Optional[Any] = ..., variables_collections: Optional[Any] = ..., outputs_collections: Optional[Any] = ..., trainable: bool = ..., begin_norm_axis: int = ..., begin_params_axis: int = ..., scope: Optional[Any] = ...): ...
def images_to_sequence(inputs: Any, data_format: Any = ..., outputs_collections: Optional[Any] = ..., scope: Optional[Any] = ...): ...
def max_pool2d(inputs: Any, kernel_size: Any, stride: int = ..., padding: str = ..., data_format: Any = ..., outputs_collections: Optional[Any] = ..., scope: Optional[Any] = ...): ...
def max_pool3d(inputs: Any, kernel_size: Any, stride: int = ..., padding: str = ..., data_format: Any = ..., outputs_collections: Optional[Any] = ..., scope: Optional[Any] = ...): ...
def pool(inputs: Any, kernel_size: Any, pooling_type: Any, padding: str = ..., data_format: Optional[Any] = ..., dilation_rate: int = ..., stride: int = ..., outputs_collections: Optional[Any] = ..., scope: Optional[Any] = ...): ...
def one_hot_encoding(labels: Any, num_classes: Any, on_value: float = ..., off_value: float = ..., outputs_collections: Optional[Any] = ..., scope: Optional[Any] = ...): ...
def repeat(inputs: Any, repetitions: Any, layer: Any, *args: Any, **kwargs: Any): ...
def scale_gradient(inputs: Any, gradient_multiplier: Any): ...
def separable_convolution2d(inputs: Any, num_outputs: Any, kernel_size: Any, depth_multiplier: int = ..., stride: int = ..., padding: str = ..., data_format: Any = ..., rate: int = ..., activation_fn: Any = ..., normalizer_fn: Optional[Any] = ..., normalizer_params: Optional[Any] = ..., weights_initializer: Any = ..., pointwise_initializer: Optional[Any] = ..., weights_regularizer: Optional[Any] = ..., biases_initializer: Any = ..., biases_regularizer: Optional[Any] = ..., reuse: Optional[Any] = ..., variables_collections: Optional[Any] = ..., outputs_collections: Optional[Any] = ..., trainable: bool = ..., scope: Optional[Any] = ...): ...
def sequence_to_images(inputs: Any, height: Any, output_data_format: str = ..., outputs_collections: Optional[Any] = ..., scope: Optional[Any] = ...): ...
def softmax(logits: Any, scope: Optional[Any] = ...): ...
def spatial_softmax(features: Any, temperature: Optional[Any] = ..., name: Optional[Any] = ..., variables_collections: Optional[Any] = ..., trainable: bool = ..., data_format: str = ...): ...
def stack(inputs: Any, layer: Any, stack_args: Any, **kwargs: Any): ...
def unit_norm(inputs: Any, dim: Any, epsilon: float = ..., scope: Optional[Any] = ...): ...
def maxout(inputs: Any, num_units: Any, axis: int = ..., scope: Optional[Any] = ...): ...
def legacy_fully_connected(x: Any, num_output_units: Any, activation_fn: Optional[Any] = ..., weight_init: Any = ..., bias_init: Any = ..., name: Optional[Any] = ..., weight_collections: Any = ..., bias_collections: Any = ..., output_collections: Any = ..., trainable: bool = ..., weight_regularizer: Optional[Any] = ..., bias_regularizer: Optional[Any] = ...): ...

elu: Any
legacy_relu: Any
legacy_linear: Any
relu: Any
relu6: Any
linear: Any
conv1d = convolution1d
conv2d = convolution2d
conv3d = convolution3d
conv2d_transpose = convolution2d_transpose
conv3d_transpose = convolution3d_transpose
conv2d_in_plane = convolution2d_in_plane
separable_conv2d = separable_convolution2d
