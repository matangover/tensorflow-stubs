# Stubs for tensorflow.contrib.tpu.python.tpu.tpu_feed (Python 3)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

from tensorflow.compiler.xla.experimental.xla_sharding import xla_sharding as xla_sharding
from tensorflow.compiler.xla.python_api import xla_shape as xla_shape
from tensorflow.contrib.tpu.python.ops import tpu_ops as tpu_ops
from tensorflow.contrib.tpu.python.tpu import tpu as tpu, tpu_sharding as tpu_sharding
from tensorflow.python.framework import dtypes as dtypes, ops as ops, tensor_shape as tensor_shape
from tensorflow.python.ops import array_ops as array_ops
from tensorflow.python.util import nest as nest
from typing import Any as Any, Optional as Optional

class InfeedQueue:
    def __init__(self, number_of_tuple_elements: Optional[Any] = ..., tuple_types: Optional[Any] = ..., tuple_shapes: Optional[Any] = ..., shard_dimensions: Optional[Any] = ..., name: Optional[Any] = ...) -> None: ...
    @property
    def number_of_tuple_elements(self): ...
    @property
    def tuple_types(self): ...
    def set_tuple_types(self, tuple_types: Any) -> None: ...
    @property
    def tuple_shapes(self): ...
    def set_tuple_shapes(self, tuple_shapes: Any) -> None: ...
    @property
    def sharding_policies(self): ...
    @property
    def shard_dimensions(self): ...
    def set_shard_dimensions(self, shard_dimensions: Any) -> None: ...
    @property
    def number_of_shards(self): ...
    def set_number_of_shards(self, number_of_shards: Any) -> None: ...
    def set_configuration_from_input_tensors(self, input_tensors: Any) -> None: ...
    def set_configuration_from_sharded_input_tensors(self, input_tensors: Any) -> None: ...
    def freeze(self) -> None: ...
    def generate_dequeue_op(self, tpu_device: int = ...): ...
    def generate_enqueue_ops(self, sharded_inputs: Any, tpu_ordinal_function: Optional[Any] = ..., placement_function: Optional[Any] = ...): ...
    def split_inputs_and_generate_enqueue_ops(self, inputs: Any, device_assignment: Optional[Any] = ..., placement_function: Optional[Any] = ..., tpu_ordinal_function: Optional[Any] = ...): ...

class _PartitionedInfeedQueue(InfeedQueue):
    def __init__(self, number_of_tuple_elements: Any, device_assignment: Any, host_id: Any, input_partition_dims: Optional[Any] = ..., tuple_types: Optional[Any] = ..., tuple_shapes: Optional[Any] = ..., name: Optional[Any] = ...) -> None: ...
    def generate_dequeue_op(self, tpu_device: int = ...): ...
    def generate_enqueue_ops(self, per_host_sharded_inputs: Any): ...
