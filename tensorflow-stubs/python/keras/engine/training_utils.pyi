# Stubs for tensorflow.python.keras.engine.training_utils (Python 3)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

from tensorflow.python.data.ops import dataset_ops as dataset_ops, iterator_ops as iterator_ops
from tensorflow.python.eager import context as context
from tensorflow.python.framework import constant_op as constant_op, ops as ops, tensor_util as tensor_util
from tensorflow.python.keras import losses as losses
from tensorflow.python.keras.engine import base_layer as base_layer
from tensorflow.python.ops import array_ops as array_ops, math_ops as math_ops, weights_broadcast_ops as weights_broadcast_ops
from tensorflow.python.util import nest as nest
from typing import Any as Any, Optional as Optional

def convert_to_iterator(x: Optional[Any] = ..., y: Optional[Any] = ..., sample_weights: Optional[Any] = ..., batch_size: Optional[Any] = ..., steps_per_epoch: Optional[Any] = ..., epochs: int = ..., shuffle: bool = ...): ...
def check_num_samples(ins: Any, batch_size: Optional[Any] = ..., steps: Optional[Any] = ..., steps_name: str = ...): ...
def standardize_single_array(x: Any): ...
def standardize_input_data(data: Any, names: Any, shapes: Optional[Any] = ..., check_batch_axis: bool = ..., exception_prefix: str = ...): ...
def standardize_sample_or_class_weights(x_weight: Any, output_names: Any, weight_type: Any): ...
def standardize_class_weights(class_weight: Any, output_names: Any): ...
def standardize_sample_weights(sample_weight: Any, output_names: Any): ...
def check_array_lengths(inputs: Any, targets: Any, weights: Optional[Any] = ...): ...
def check_loss_and_target_compatibility(targets: Any, loss_fns: Any, output_shapes: Any) -> None: ...
def collect_per_output_metric_info(metrics: Any, output_names: Any, output_shapes: Any, loss_fns: Any, sample_weights: Optional[Any] = ...): ...
def batch_shuffle(index_array: Any, batch_size: Any): ...
def weighted_masked_objective(fn: Any): ...
def standardize_weights(y: Any, sample_weight: Optional[Any] = ..., class_weight: Optional[Any] = ..., sample_weight_mode: Optional[Any] = ...): ...
def has_symbolic_tensors(ls: Any): ...
def has_tensors(ls: Any): ...
def get_metric_name(metric: Any, weighted: bool = ...): ...
def get_metric_function(metric: Any, output_shape: Optional[Any] = ..., loss_fn: Optional[Any] = ...): ...
def validate_iterator_input(x: Any, y: Any, sample_weight: Any, validation_split: Optional[Any] = ...) -> None: ...
def check_generator_arguments(y: Optional[Any] = ..., sample_weight: Optional[Any] = ...) -> None: ...
def check_steps_argument(input_data: Any, steps: Any, steps_name: Any): ...
def cast_single_tensor(x: Any): ...
def cast_if_floating_dtype(x: Any): ...
def get_output_sample_weight_and_mode(skip_target_weighing_indices: Any, sample_weight_mode: Any, output_name: Any, output_index: Any): ...
def prepare_sample_weights(output_names: Any, sample_weight_mode: Any, skip_target_weighing_indices: Any): ...
def is_feature_layer(layer: Any): ...

class ModelInputs:
    def __init__(self, inputs: Any) -> None: ...
    def get_input_names(self): ...
    def get_input_values(self): ...
    def get_symbolic_inputs(self, return_single_as_list: bool = ...): ...
    def as_dict(self) -> None: ...
    def as_list(self): ...
