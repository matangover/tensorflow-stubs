# Stubs for tensorflow.python.keras.utils.data_utils (Python 3)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

import abc as abc
from abc import abstractmethod as abstractmethod
from tensorflow.python.keras.utils.generic_utils import Progbar as Progbar
from tensorflow.python.util import tf_inspect as tf_inspect
from tensorflow.python.util.tf_export import tf_export as tf_export
from typing import Any as Any, Optional as Optional

def urlretrieve(url: Any, filename: Any, reporthook: Optional[Any] = ..., data: Optional[Any] = ...) -> None: ...
def is_generator_or_sequence(x: Any): ...
def get_file(fname: Any, origin: Any, untar: bool = ..., md5_hash: Optional[Any] = ..., file_hash: Optional[Any] = ..., cache_subdir: str = ..., hash_algorithm: str = ..., extract: bool = ..., archive_format: str = ..., cache_dir: Optional[Any] = ...): ...
def validate_file(fpath: Any, file_hash: Any, algorithm: str = ..., chunk_size: int = ...): ...

class Sequence(metaclass=abc.ABCMeta):
    @abstractmethod
    def __getitem__(self, index: Any) -> Any: ...
    @abstractmethod
    def __len__(self) -> Any: ...
    def on_epoch_end(self) -> None: ...
    def __iter__(self) -> None: ...

def init_pool(seqs: Any) -> None: ...
def get_index(uid: Any, i: Any): ...

class SequenceEnqueuer(metaclass=abc.ABCMeta):
    @abstractmethod
    def is_running(self) -> Any: ...
    @abstractmethod
    def start(self, workers: int = ..., max_queue_size: int = ...) -> Any: ...
    @abstractmethod
    def stop(self, timeout: Optional[Any] = ...) -> Any: ...
    @abstractmethod
    def get(self) -> Any: ...

class OrderedEnqueuer(SequenceEnqueuer):
    sequence: Any = ...
    use_multiprocessing: Any = ...
    uid: Any = ...
    shuffle: Any = ...
    workers: int = ...
    executor_fn: Any = ...
    queue: Any = ...
    run_thread: Any = ...
    stop_signal: Any = ...
    def __init__(self, sequence: Any, use_multiprocessing: bool = ..., shuffle: bool = ...) -> None: ...
    def is_running(self): ...
    def start(self, workers: int = ..., max_queue_size: int = ...): ...
    def get(self) -> None: ...
    def stop(self, timeout: Optional[Any] = ...) -> None: ...

class GeneratorEnqueuer(SequenceEnqueuer):
    wait_time: Any = ...
    queue: Any = ...
    seed: Any = ...
    def __init__(self, generator: Any, use_multiprocessing: bool = ..., wait_time: float = ..., seed: Optional[Any] = ...) -> None: ...
    max_queue_size: Any = ...
    genlock: Any = ...
    def start(self, workers: int = ..., max_queue_size: int = ...) -> None: ...
    def is_running(self): ...
    def stop(self, timeout: Optional[Any] = ...) -> None: ...
    def get(self) -> None: ...
