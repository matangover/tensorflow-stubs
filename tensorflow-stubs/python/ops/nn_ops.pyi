# Stubs for tensorflow.python.ops.nn_ops (Python 3)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

from tensorflow.python.ops.gen_nn_ops import *
from tensorflow.python.eager import context as context
from tensorflow.python.framework import dtypes as dtypes, graph_util as graph_util, ops as ops, tensor_shape as tensor_shape, tensor_util as tensor_util
from tensorflow.python.ops import array_ops as array_ops, check_ops as check_ops, gen_nn_ops as gen_nn_ops, math_ops as math_ops, random_ops as random_ops
from tensorflow.python.util import deprecation as deprecation
from tensorflow.python.util.tf_export import tf_export as tf_export
from typing import Any as Any, Optional as Optional

local_response_normalization = gen_nn_ops.lrn

class _NonAtrousConvolution:
    padding: Any = ...
    name: Any = ...
    strides: Any = ...
    data_format: Any = ...
    conv_op: Any = ...
    def __init__(self, input_shape: Any, filter_shape: Any, padding: Any, data_format: Optional[Any] = ..., strides: Optional[Any] = ..., name: Optional[Any] = ...) -> None: ...
    def __call__(self, inp: Any, filter: Any): ...

def with_space_to_batch(input: Any, dilation_rate: Any, padding: Any, op: Any, filter_shape: Optional[Any] = ..., spatial_dims: Optional[Any] = ..., data_format: Optional[Any] = ...): ...

class _WithSpaceToBatch:
    call: Any = ...
    base_paddings: Any = ...
    num_spatial_dims: Any = ...
    rate_or_const_rate: Any = ...
    input_shape: Any = ...
    spatial_dims: Any = ...
    dilation_rate: Any = ...
    data_format: Any = ...
    op: Any = ...
    def __init__(self, input_shape: Any, dilation_rate: Any, padding: Any, build_op: Any, filter_shape: Optional[Any] = ..., spatial_dims: Optional[Any] = ..., data_format: Optional[Any] = ...) -> None: ...
    def __call__(self, inp: Any, filter: Any): ...

def convolution(input: Any, filter: Any, padding: Any, strides: Optional[Any] = ..., dilation_rate: Optional[Any] = ..., name: Optional[Any] = ..., data_format: Optional[Any] = ...): ...

class Convolution:
    input_shape: Any = ...
    filter_shape: Any = ...
    data_format: Any = ...
    strides: Any = ...
    name: Any = ...
    conv_op: Any = ...
    def __init__(self, input_shape: Any, filter_shape: Any, padding: Any, strides: Optional[Any] = ..., dilation_rate: Optional[Any] = ..., name: Optional[Any] = ..., data_format: Optional[Any] = ...) -> None: ...
    def __call__(self, inp: Any, filter: Any): ...

def pool(input: Any, window_shape: Any, pooling_type: Any, padding: Any, dilation_rate: Optional[Any] = ..., strides: Optional[Any] = ..., name: Optional[Any] = ..., data_format: Optional[Any] = ...): ...
def atrous_conv2d(value: Any, filters: Any, rate: Any, padding: Any, name: Optional[Any] = ...): ...
def conv2d_transpose(value: Any, filter: Any, output_shape: Any, strides: Any, padding: str = ..., data_format: str = ..., name: Optional[Any] = ...): ...
def atrous_conv2d_transpose(value: Any, filters: Any, output_shape: Any, rate: Any, padding: Any, name: Optional[Any] = ...): ...
def conv3d_transpose(value: Any, filter: Any, output_shape: Any, strides: Any, padding: str = ..., data_format: str = ..., name: Optional[Any] = ...): ...
def bias_add(value: Any, bias: Any, data_format: Optional[Any] = ..., name: Optional[Any] = ...): ...
def bias_add_v1(value: Any, bias: Any, name: Optional[Any] = ...): ...
def crelu(features: Any, name: Optional[Any] = ..., axis: int = ...): ...
def relu6(features: Any, name: Optional[Any] = ...): ...
def leaky_relu(features: Any, alpha: float = ..., name: Optional[Any] = ...): ...
def softmax(logits: Any, axis: Optional[Any] = ..., name: Optional[Any] = ..., dim: Optional[Any] = ...): ...
def log_softmax(logits: Any, axis: Optional[Any] = ..., name: Optional[Any] = ..., dim: Optional[Any] = ...): ...
def softmax_cross_entropy_with_logits_v2(_sentinel: Optional[Any] = ..., labels: Optional[Any] = ..., logits: Optional[Any] = ..., dim: int = ..., name: Optional[Any] = ...): ...
def softmax_cross_entropy_with_logits(_sentinel: Optional[Any] = ..., labels: Optional[Any] = ..., logits: Optional[Any] = ..., dim: int = ..., name: Optional[Any] = ...): ...
def sparse_softmax_cross_entropy_with_logits(_sentinel: Optional[Any] = ..., labels: Optional[Any] = ..., logits: Optional[Any] = ..., name: Optional[Any] = ...): ...
def avg_pool(value: Any, ksize: Any, strides: Any, padding: Any, data_format: str = ..., name: Optional[Any] = ...): ...
def max_pool(value: Any, ksize: Any, strides: Any, padding: Any, data_format: str = ..., name: Optional[Any] = ...): ...
def xw_plus_b(x: Any, weights: Any, biases: Any, name: Optional[Any] = ...): ...
def xw_plus_b_v1(x: Any, weights: Any, biases: Any, name: Optional[Any] = ...): ...
def dropout(x: Any, keep_prob: Any, noise_shape: Optional[Any] = ..., seed: Optional[Any] = ..., name: Optional[Any] = ...): ...
def top_k(input: Any, k: int = ..., sorted: bool = ..., name: Optional[Any] = ...): ...
def nth_element(input: Any, n: Any, reverse: bool = ..., name: Optional[Any] = ...): ...
def conv1d(value: Any, filters: Any, stride: Any, padding: Any, use_cudnn_on_gpu: Optional[Any] = ..., data_format: Optional[Any] = ..., name: Optional[Any] = ...): ...
def conv1d_transpose(value: Any, filter: Any, output_shape: Any, stride: Any, padding: str = ..., data_format: str = ..., name: Optional[Any] = ...): ...
def erosion2d(value: Any, kernel: Any, strides: Any, rates: Any, padding: Any, name: Optional[Any] = ...): ...
def in_top_k(predictions: Any, targets: Any, k: Any, name: Optional[Any] = ...): ...
