# Stubs for tensorflow.python.keras.layers.recurrent (Python 3)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

from tensorflow.python.eager import context as context
from tensorflow.python.framework import tensor_shape as tensor_shape
from tensorflow.python.keras import activations as activations, constraints as constraints, initializers as initializers, regularizers as regularizers
from tensorflow.python.keras.engine.base_layer import InputSpec as InputSpec, Layer as Layer
from tensorflow.python.keras.utils import generic_utils as generic_utils, tf_utils as tf_utils
from tensorflow.python.ops import array_ops as array_ops, state_ops as state_ops
from tensorflow.python.util import nest as nest
from tensorflow.python.util.tf_export import tf_export as tf_export
from typing import Any as Any, Optional as Optional

class StackedRNNCells(Layer):
    cells: Any = ...
    reverse_state_order: Any = ...
    def __init__(self, cells: Any, **kwargs: Any) -> None: ...
    @property
    def state_size(self): ...
    @property
    def output_size(self): ...
    def get_initial_state(self, inputs: Optional[Any] = ..., batch_size: Optional[Any] = ..., dtype: Optional[Any] = ...): ...
    def call(self, inputs: Any, states: Any, constants: Optional[Any] = ..., **kwargs: Any): ...
    built: bool = ...
    def build(self, input_shape: Any) -> None: ...
    def get_config(self): ...
    @classmethod
    def from_config(cls, config: Any, custom_objects: Optional[Any] = ...): ...
    @property
    def trainable_weights(self): ...
    @property
    def non_trainable_weights(self): ...
    def get_weights(self): ...
    def set_weights(self, weights: Any) -> None: ...
    @property
    def losses(self): ...
    @property
    def updates(self): ...

class RNN(Layer):
    cell: Any = ...
    return_sequences: Any = ...
    return_state: Any = ...
    go_backwards: Any = ...
    stateful: Any = ...
    unroll: Any = ...
    supports_masking: bool = ...
    input_spec: Any = ...
    state_spec: Any = ...
    constants_spec: Any = ...
    def __init__(self, cell: Any, return_sequences: bool = ..., return_state: bool = ..., go_backwards: bool = ..., stateful: bool = ..., unroll: bool = ..., **kwargs: Any) -> None: ...
    @property
    def states(self): ...
    @states.setter
    def states(self, states: Any) -> None: ...
    def compute_output_shape(self, input_shape: Any): ...
    def compute_mask(self, inputs: Any, mask: Any): ...
    built: bool = ...
    def build(self, input_shape: Any) -> None: ...
    def get_initial_state(self, inputs: Any): ...
    def __call__(self, inputs: Any, initial_state: Optional[Any] = ..., constants: Optional[Any] = ..., **kwargs: Any): ...
    def call(self, inputs: Any, mask: Optional[Any] = ..., training: Optional[Any] = ..., initial_state: Optional[Any] = ..., constants: Optional[Any] = ...): ...
    states: Any = ...
    def reset_states(self, states: Optional[Any] = ...) -> None: ...
    def get_config(self): ...
    @classmethod
    def from_config(cls, config: Any, custom_objects: Optional[Any] = ...): ...
    @property
    def trainable_weights(self): ...
    @property
    def non_trainable_weights(self): ...
    @property
    def losses(self): ...
    @property
    def updates(self): ...

class SimpleRNNCell(Layer):
    units: Any = ...
    activation: Any = ...
    use_bias: Any = ...
    kernel_initializer: Any = ...
    recurrent_initializer: Any = ...
    bias_initializer: Any = ...
    kernel_regularizer: Any = ...
    recurrent_regularizer: Any = ...
    bias_regularizer: Any = ...
    kernel_constraint: Any = ...
    recurrent_constraint: Any = ...
    bias_constraint: Any = ...
    dropout: Any = ...
    recurrent_dropout: Any = ...
    state_size: Any = ...
    output_size: Any = ...
    def __init__(self, units: Any, activation: str = ..., use_bias: bool = ..., kernel_initializer: str = ..., recurrent_initializer: str = ..., bias_initializer: str = ..., kernel_regularizer: Optional[Any] = ..., recurrent_regularizer: Optional[Any] = ..., bias_regularizer: Optional[Any] = ..., kernel_constraint: Optional[Any] = ..., recurrent_constraint: Optional[Any] = ..., bias_constraint: Optional[Any] = ..., dropout: float = ..., recurrent_dropout: float = ..., **kwargs: Any) -> None: ...
    kernel: Any = ...
    recurrent_kernel: Any = ...
    bias: Any = ...
    built: bool = ...
    def build(self, input_shape: Any) -> None: ...
    def call(self, inputs: Any, states: Any, training: Optional[Any] = ...): ...
    def get_initial_state(self, inputs: Optional[Any] = ..., batch_size: Optional[Any] = ..., dtype: Optional[Any] = ...): ...
    def get_config(self): ...

class SimpleRNN(RNN):
    activity_regularizer: Any = ...
    def __init__(self, units: Any, activation: str = ..., use_bias: bool = ..., kernel_initializer: str = ..., recurrent_initializer: str = ..., bias_initializer: str = ..., kernel_regularizer: Optional[Any] = ..., recurrent_regularizer: Optional[Any] = ..., bias_regularizer: Optional[Any] = ..., activity_regularizer: Optional[Any] = ..., kernel_constraint: Optional[Any] = ..., recurrent_constraint: Optional[Any] = ..., bias_constraint: Optional[Any] = ..., dropout: float = ..., recurrent_dropout: float = ..., return_sequences: bool = ..., return_state: bool = ..., go_backwards: bool = ..., stateful: bool = ..., unroll: bool = ..., **kwargs: Any) -> None: ...
    def call(self, inputs: Any, mask: Optional[Any] = ..., training: Optional[Any] = ..., initial_state: Optional[Any] = ...): ...
    @property
    def units(self): ...
    @property
    def activation(self): ...
    @property
    def use_bias(self): ...
    @property
    def kernel_initializer(self): ...
    @property
    def recurrent_initializer(self): ...
    @property
    def bias_initializer(self): ...
    @property
    def kernel_regularizer(self): ...
    @property
    def recurrent_regularizer(self): ...
    @property
    def bias_regularizer(self): ...
    @property
    def kernel_constraint(self): ...
    @property
    def recurrent_constraint(self): ...
    @property
    def bias_constraint(self): ...
    @property
    def dropout(self): ...
    @property
    def recurrent_dropout(self): ...
    def get_config(self): ...
    @classmethod
    def from_config(cls, config: Any): ...

class GRUCell(Layer):
    units: Any = ...
    activation: Any = ...
    recurrent_activation: Any = ...
    use_bias: Any = ...
    kernel_initializer: Any = ...
    recurrent_initializer: Any = ...
    bias_initializer: Any = ...
    kernel_regularizer: Any = ...
    recurrent_regularizer: Any = ...
    bias_regularizer: Any = ...
    kernel_constraint: Any = ...
    recurrent_constraint: Any = ...
    bias_constraint: Any = ...
    dropout: Any = ...
    recurrent_dropout: Any = ...
    implementation: Any = ...
    reset_after: Any = ...
    state_size: Any = ...
    output_size: Any = ...
    def __init__(self, units: Any, activation: str = ..., recurrent_activation: str = ..., use_bias: bool = ..., kernel_initializer: str = ..., recurrent_initializer: str = ..., bias_initializer: str = ..., kernel_regularizer: Optional[Any] = ..., recurrent_regularizer: Optional[Any] = ..., bias_regularizer: Optional[Any] = ..., kernel_constraint: Optional[Any] = ..., recurrent_constraint: Optional[Any] = ..., bias_constraint: Optional[Any] = ..., dropout: float = ..., recurrent_dropout: float = ..., implementation: int = ..., reset_after: bool = ..., **kwargs: Any) -> None: ...
    kernel: Any = ...
    recurrent_kernel: Any = ...
    bias: Any = ...
    input_bias: Any = ...
    recurrent_bias: Any = ...
    built: bool = ...
    def build(self, input_shape: Any) -> None: ...
    def call(self, inputs: Any, states: Any, training: Optional[Any] = ...): ...
    def get_config(self): ...
    def get_initial_state(self, inputs: Optional[Any] = ..., batch_size: Optional[Any] = ..., dtype: Optional[Any] = ...): ...

class GRU(RNN):
    activity_regularizer: Any = ...
    def __init__(self, units: Any, activation: str = ..., recurrent_activation: str = ..., use_bias: bool = ..., kernel_initializer: str = ..., recurrent_initializer: str = ..., bias_initializer: str = ..., kernel_regularizer: Optional[Any] = ..., recurrent_regularizer: Optional[Any] = ..., bias_regularizer: Optional[Any] = ..., activity_regularizer: Optional[Any] = ..., kernel_constraint: Optional[Any] = ..., recurrent_constraint: Optional[Any] = ..., bias_constraint: Optional[Any] = ..., dropout: float = ..., recurrent_dropout: float = ..., implementation: int = ..., return_sequences: bool = ..., return_state: bool = ..., go_backwards: bool = ..., stateful: bool = ..., unroll: bool = ..., reset_after: bool = ..., **kwargs: Any) -> None: ...
    def call(self, inputs: Any, mask: Optional[Any] = ..., training: Optional[Any] = ..., initial_state: Optional[Any] = ...): ...
    @property
    def units(self): ...
    @property
    def activation(self): ...
    @property
    def recurrent_activation(self): ...
    @property
    def use_bias(self): ...
    @property
    def kernel_initializer(self): ...
    @property
    def recurrent_initializer(self): ...
    @property
    def bias_initializer(self): ...
    @property
    def kernel_regularizer(self): ...
    @property
    def recurrent_regularizer(self): ...
    @property
    def bias_regularizer(self): ...
    @property
    def kernel_constraint(self): ...
    @property
    def recurrent_constraint(self): ...
    @property
    def bias_constraint(self): ...
    @property
    def dropout(self): ...
    @property
    def recurrent_dropout(self): ...
    @property
    def implementation(self): ...
    @property
    def reset_after(self): ...
    def get_config(self): ...
    @classmethod
    def from_config(cls, config: Any): ...

class LSTMCell(Layer):
    units: Any = ...
    activation: Any = ...
    recurrent_activation: Any = ...
    use_bias: Any = ...
    kernel_initializer: Any = ...
    recurrent_initializer: Any = ...
    bias_initializer: Any = ...
    unit_forget_bias: Any = ...
    kernel_regularizer: Any = ...
    recurrent_regularizer: Any = ...
    bias_regularizer: Any = ...
    kernel_constraint: Any = ...
    recurrent_constraint: Any = ...
    bias_constraint: Any = ...
    dropout: Any = ...
    recurrent_dropout: Any = ...
    implementation: Any = ...
    state_size: Any = ...
    output_size: Any = ...
    def __init__(self, units: Any, activation: str = ..., recurrent_activation: str = ..., use_bias: bool = ..., kernel_initializer: str = ..., recurrent_initializer: str = ..., bias_initializer: str = ..., unit_forget_bias: bool = ..., kernel_regularizer: Optional[Any] = ..., recurrent_regularizer: Optional[Any] = ..., bias_regularizer: Optional[Any] = ..., kernel_constraint: Optional[Any] = ..., recurrent_constraint: Optional[Any] = ..., bias_constraint: Optional[Any] = ..., dropout: float = ..., recurrent_dropout: float = ..., implementation: int = ..., **kwargs: Any) -> None: ...
    kernel: Any = ...
    recurrent_kernel: Any = ...
    bias: Any = ...
    built: bool = ...
    def build(self, input_shape: Any): ...
    def call(self, inputs: Any, states: Any, training: Optional[Any] = ...): ...
    def get_config(self): ...
    def get_initial_state(self, inputs: Optional[Any] = ..., batch_size: Optional[Any] = ..., dtype: Optional[Any] = ...): ...

class LSTM(RNN):
    activity_regularizer: Any = ...
    def __init__(self, units: Any, activation: str = ..., recurrent_activation: str = ..., use_bias: bool = ..., kernel_initializer: str = ..., recurrent_initializer: str = ..., bias_initializer: str = ..., unit_forget_bias: bool = ..., kernel_regularizer: Optional[Any] = ..., recurrent_regularizer: Optional[Any] = ..., bias_regularizer: Optional[Any] = ..., activity_regularizer: Optional[Any] = ..., kernel_constraint: Optional[Any] = ..., recurrent_constraint: Optional[Any] = ..., bias_constraint: Optional[Any] = ..., dropout: float = ..., recurrent_dropout: float = ..., implementation: int = ..., return_sequences: bool = ..., return_state: bool = ..., go_backwards: bool = ..., stateful: bool = ..., unroll: bool = ..., **kwargs: Any) -> None: ...
    def call(self, inputs: Any, mask: Optional[Any] = ..., training: Optional[Any] = ..., initial_state: Optional[Any] = ...): ...
    @property
    def units(self): ...
    @property
    def activation(self): ...
    @property
    def recurrent_activation(self): ...
    @property
    def use_bias(self): ...
    @property
    def kernel_initializer(self): ...
    @property
    def recurrent_initializer(self): ...
    @property
    def bias_initializer(self): ...
    @property
    def unit_forget_bias(self): ...
    @property
    def kernel_regularizer(self): ...
    @property
    def recurrent_regularizer(self): ...
    @property
    def bias_regularizer(self): ...
    @property
    def kernel_constraint(self): ...
    @property
    def recurrent_constraint(self): ...
    @property
    def bias_constraint(self): ...
    @property
    def dropout(self): ...
    @property
    def recurrent_dropout(self): ...
    @property
    def implementation(self): ...
    def get_config(self): ...
    @classmethod
    def from_config(cls, config: Any): ...
