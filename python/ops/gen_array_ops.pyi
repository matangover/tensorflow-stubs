# Stubs for tensorflow.python.ops.gen_array_ops (Python 3)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

from collections import namedtuple as namedtuple
from tensorflow.python.util.deprecation import deprecated_endpoints as deprecated_endpoints
from tensorflow.python.util.tf_export import tf_export as tf_export
from typing import Any as Any, Optional as Optional

def batch_matrix_band_part(input: Any, num_lower: Any, num_upper: Any, name: Optional[Any] = ...): ...
def batch_matrix_band_part_eager_fallback(input: Any, num_lower: Any, num_upper: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def batch_matrix_diag(diagonal: Any, name: Optional[Any] = ...): ...
def batch_matrix_diag_eager_fallback(diagonal: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def batch_matrix_diag_part(input: Any, name: Optional[Any] = ...): ...
def batch_matrix_diag_part_eager_fallback(input: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def batch_matrix_set_diag(input: Any, diagonal: Any, name: Optional[Any] = ...): ...
def batch_matrix_set_diag_eager_fallback(input: Any, diagonal: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def batch_to_space(input: Any, crops: Any, block_size: Any, name: Optional[Any] = ...): ...
def batch_to_space_eager_fallback(input: Any, crops: Any, block_size: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def batch_to_space_nd(input: Any, block_shape: Any, crops: Any, name: Optional[Any] = ...): ...
def batch_to_space_nd_eager_fallback(input: Any, block_shape: Any, crops: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def bitcast(input: Any, type: Any, name: Optional[Any] = ...): ...
def bitcast_eager_fallback(input: Any, type: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def broadcast_args(s0: Any, s1: Any, name: Optional[Any] = ...): ...
def broadcast_args_eager_fallback(s0: Any, s1: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _BroadcastGradientArgsOutput = namedtuple('BroadcastGradientArgs', <ERROR>)

def broadcast_gradient_args(s0: Any, s1: Any, name: Optional[Any] = ...): ...
def broadcast_gradient_args_eager_fallback(s0: Any, s1: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def broadcast_to(input: Any, shape: Any, name: Optional[Any] = ...): ...
def broadcast_to_eager_fallback(input: Any, shape: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def check_numerics(tensor: Any, message: Any, name: Optional[Any] = ...): ...
def check_numerics_eager_fallback(tensor: Any, message: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def concat(concat_dim: Any, values: Any, name: Optional[Any] = ...): ...
def concat_eager_fallback(concat_dim: Any, values: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def concat_offset(concat_dim: Any, shape: Any, name: Optional[Any] = ...): ...
def concat_offset_eager_fallback(concat_dim: Any, shape: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def concat_v2(values: Any, axis: Any, name: Optional[Any] = ...): ...
def concat_v2_eager_fallback(values: Any, axis: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def conjugate_transpose(x: Any, perm: Any, name: Optional[Any] = ...): ...
def conjugate_transpose_eager_fallback(x: Any, perm: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def const(value: Any, dtype: Any, name: Optional[Any] = ...): ...
def const_eager_fallback(value: Any, dtype: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def debug_gradient_identity(input: Any, name: Optional[Any] = ...): ...
def debug_gradient_identity_eager_fallback(input: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def debug_gradient_ref_identity(input: Any, name: Optional[Any] = ...): ...
def deep_copy(x: Any, name: Optional[Any] = ...): ...
def deep_copy_eager_fallback(x: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def depth_to_space(input: Any, block_size: Any, data_format: str = ..., name: Optional[Any] = ...): ...
def depth_to_space_eager_fallback(input: Any, block_size: Any, data_format: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def dequantize(input: Any, min_range: Any, max_range: Any, mode: str = ..., name: Optional[Any] = ...): ...
def dequantize_eager_fallback(input: Any, min_range: Any, max_range: Any, mode: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def diag(diagonal: Any, name: Optional[Any] = ...): ...
def diag_eager_fallback(diagonal: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def diag_part(input: Any, name: Optional[Any] = ...): ...
def diag_part_eager_fallback(input: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def edit_distance(hypothesis_indices: Any, hypothesis_values: Any, hypothesis_shape: Any, truth_indices: Any, truth_values: Any, truth_shape: Any, normalize: bool = ..., name: Optional[Any] = ...): ...
def edit_distance_eager_fallback(hypothesis_indices: Any, hypothesis_values: Any, hypothesis_shape: Any, truth_indices: Any, truth_values: Any, truth_shape: Any, normalize: bool = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def empty(shape: Any, dtype: Any, init: bool = ..., name: Optional[Any] = ...): ...
def empty_eager_fallback(shape: Any, dtype: Any, init: bool = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def ensure_shape(input: Any, shape: Any, name: Optional[Any] = ...): ...
def ensure_shape_eager_fallback(input: Any, shape: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def expand_dims(input: Any, axis: Any, name: Optional[Any] = ...): ...
def expand_dims_eager_fallback(input: Any, axis: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def extract_image_patches(images: Any, ksizes: Any, strides: Any, rates: Any, padding: Any, name: Optional[Any] = ...): ...
def extract_image_patches_eager_fallback(images: Any, ksizes: Any, strides: Any, rates: Any, padding: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def extract_volume_patches(input: Any, ksizes: Any, strides: Any, padding: Any, name: Optional[Any] = ...): ...
def extract_volume_patches_eager_fallback(input: Any, ksizes: Any, strides: Any, padding: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def fake_quant_with_min_max_args(inputs: Any, min: int = ..., max: int = ..., num_bits: int = ..., narrow_range: bool = ..., name: Optional[Any] = ...): ...
def fake_quant_with_min_max_args_eager_fallback(inputs: Any, min: int = ..., max: int = ..., num_bits: int = ..., narrow_range: bool = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def fake_quant_with_min_max_args_gradient(gradients: Any, inputs: Any, min: int = ..., max: int = ..., num_bits: int = ..., narrow_range: bool = ..., name: Optional[Any] = ...): ...
def fake_quant_with_min_max_args_gradient_eager_fallback(gradients: Any, inputs: Any, min: int = ..., max: int = ..., num_bits: int = ..., narrow_range: bool = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def fake_quant_with_min_max_vars(inputs: Any, min: Any, max: Any, num_bits: int = ..., narrow_range: bool = ..., name: Optional[Any] = ...): ...
def fake_quant_with_min_max_vars_eager_fallback(inputs: Any, min: Any, max: Any, num_bits: int = ..., narrow_range: bool = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _FakeQuantWithMinMaxVarsGradientOutput = namedtuple('FakeQuantWithMinMaxVarsGradient', <ERROR>)

def fake_quant_with_min_max_vars_gradient(gradients: Any, inputs: Any, min: Any, max: Any, num_bits: int = ..., narrow_range: bool = ..., name: Optional[Any] = ...): ...
def fake_quant_with_min_max_vars_gradient_eager_fallback(gradients: Any, inputs: Any, min: Any, max: Any, num_bits: int = ..., narrow_range: bool = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def fake_quant_with_min_max_vars_per_channel(inputs: Any, min: Any, max: Any, num_bits: int = ..., narrow_range: bool = ..., name: Optional[Any] = ...): ...
def fake_quant_with_min_max_vars_per_channel_eager_fallback(inputs: Any, min: Any, max: Any, num_bits: int = ..., narrow_range: bool = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _FakeQuantWithMinMaxVarsPerChannelGradientOutput = namedtuple('FakeQuantWithMinMaxVarsPerChannelGradient', <ERROR>)

def fake_quant_with_min_max_vars_per_channel_gradient(gradients: Any, inputs: Any, min: Any, max: Any, num_bits: int = ..., narrow_range: bool = ..., name: Optional[Any] = ...): ...
def fake_quant_with_min_max_vars_per_channel_gradient_eager_fallback(gradients: Any, inputs: Any, min: Any, max: Any, num_bits: int = ..., narrow_range: bool = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def fill(dims: Any, value: Any, name: Optional[Any] = ...): ...
def fill_eager_fallback(dims: Any, value: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def gather(params: Any, indices: Any, validate_indices: bool = ..., name: Optional[Any] = ...): ...
def gather_eager_fallback(params: Any, indices: Any, validate_indices: bool = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def gather_nd(params: Any, indices: Any, name: Optional[Any] = ...): ...
def gather_nd_eager_fallback(params: Any, indices: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def gather_v2(params: Any, indices: Any, axis: Any, name: Optional[Any] = ...): ...
def gather_v2_eager_fallback(params: Any, indices: Any, axis: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def guarantee_const(input: Any, name: Optional[Any] = ...): ...
def guarantee_const_eager_fallback(input: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def identity(input: Any, name: Optional[Any] = ...): ...
def identity_eager_fallback(input: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def identity_n(input: Any, name: Optional[Any] = ...): ...
def identity_n_eager_fallback(input: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def immutable_const(dtype: Any, shape: Any, memory_region_name: Any, name: Optional[Any] = ...): ...
def immutable_const_eager_fallback(dtype: Any, shape: Any, memory_region_name: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def inplace_add(x: Any, i: Any, v: Any, name: Optional[Any] = ...): ...
def inplace_add_eager_fallback(x: Any, i: Any, v: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def inplace_sub(x: Any, i: Any, v: Any, name: Optional[Any] = ...): ...
def inplace_sub_eager_fallback(x: Any, i: Any, v: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def inplace_update(x: Any, i: Any, v: Any, name: Optional[Any] = ...): ...
def inplace_update_eager_fallback(x: Any, i: Any, v: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def invert_permutation(x: Any, name: Optional[Any] = ...): ...
def invert_permutation_eager_fallback(x: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _ListDiffOutput = namedtuple('ListDiff', <ERROR>)

def list_diff(x: Any, y: Any, out_idx: Any = ..., name: Optional[Any] = ...): ...
def list_diff_eager_fallback(x: Any, y: Any, out_idx: Any = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def lower_bound(sorted_inputs: Any, values: Any, out_type: Any = ..., name: Optional[Any] = ...): ...
def lower_bound_eager_fallback(sorted_inputs: Any, values: Any, out_type: Any = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def matrix_band_part(input: Any, num_lower: Any, num_upper: Any, name: Optional[Any] = ...): ...
def matrix_band_part_eager_fallback(input: Any, num_lower: Any, num_upper: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def matrix_diag(diagonal: Any, name: Optional[Any] = ...): ...
def matrix_diag_eager_fallback(diagonal: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def matrix_diag_part(input: Any, name: Optional[Any] = ...): ...
def matrix_diag_part_eager_fallback(input: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def matrix_set_diag(input: Any, diagonal: Any, name: Optional[Any] = ...): ...
def matrix_set_diag_eager_fallback(input: Any, diagonal: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def mirror_pad(input: Any, paddings: Any, mode: Any, name: Optional[Any] = ...): ...
def mirror_pad_eager_fallback(input: Any, paddings: Any, mode: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def mirror_pad_grad(input: Any, paddings: Any, mode: Any, name: Optional[Any] = ...): ...
def mirror_pad_grad_eager_fallback(input: Any, paddings: Any, mode: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def one_hot(indices: Any, depth: Any, on_value: Any, off_value: Any, axis: int = ..., name: Optional[Any] = ...): ...
def one_hot_eager_fallback(indices: Any, depth: Any, on_value: Any, off_value: Any, axis: int = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def ones_like(x: Any, name: Optional[Any] = ...): ...
def ones_like_eager_fallback(x: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def pack(values: Any, axis: int = ..., name: Optional[Any] = ...): ...
def pack_eager_fallback(values: Any, axis: int = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def pad(input: Any, paddings: Any, name: Optional[Any] = ...): ...
def pad_eager_fallback(input: Any, paddings: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def pad_v2(input: Any, paddings: Any, constant_values: Any, name: Optional[Any] = ...): ...
def pad_v2_eager_fallback(input: Any, paddings: Any, constant_values: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def parallel_concat(values: Any, shape: Any, name: Optional[Any] = ...): ...
def parallel_concat_eager_fallback(values: Any, shape: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def placeholder(dtype: Any, shape: Optional[Any] = ..., name: Optional[Any] = ...): ...
def placeholder_eager_fallback(dtype: Any, shape: Optional[Any] = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def placeholder_v2(dtype: Any, shape: Any, name: Optional[Any] = ...): ...
def placeholder_v2_eager_fallback(dtype: Any, shape: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def placeholder_with_default(input: Any, shape: Any, name: Optional[Any] = ...): ...
def placeholder_with_default_eager_fallback(input: Any, shape: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def prevent_gradient(input: Any, message: str = ..., name: Optional[Any] = ...): ...
def prevent_gradient_eager_fallback(input: Any, message: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def quantize_and_dequantize(input: Any, signed_input: bool = ..., num_bits: int = ..., range_given: bool = ..., input_min: int = ..., input_max: int = ..., name: Optional[Any] = ...): ...
def quantize_and_dequantize_eager_fallback(input: Any, signed_input: bool = ..., num_bits: int = ..., range_given: bool = ..., input_min: int = ..., input_max: int = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def quantize_and_dequantize_v2(input: Any, input_min: Any, input_max: Any, signed_input: bool = ..., num_bits: int = ..., range_given: bool = ..., name: Optional[Any] = ...): ...
def quantize_and_dequantize_v2_eager_fallback(input: Any, input_min: Any, input_max: Any, signed_input: bool = ..., num_bits: int = ..., range_given: bool = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def quantize_and_dequantize_v3(input: Any, input_min: Any, input_max: Any, num_bits: Any, signed_input: bool = ..., range_given: bool = ..., name: Optional[Any] = ...): ...
def quantize_and_dequantize_v3_eager_fallback(input: Any, input_min: Any, input_max: Any, num_bits: Any, signed_input: bool = ..., range_given: bool = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _QuantizeV2Output = namedtuple('QuantizeV2', <ERROR>)

def quantize_v2(input: Any, min_range: Any, max_range: Any, T: Any, mode: str = ..., round_mode: str = ..., name: Optional[Any] = ...): ...
def quantize_v2_eager_fallback(input: Any, min_range: Any, max_range: Any, T: Any, mode: str = ..., round_mode: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _QuantizedConcatOutput = namedtuple('QuantizedConcat', <ERROR>)

def quantized_concat(concat_dim: Any, values: Any, input_mins: Any, input_maxes: Any, name: Optional[Any] = ...): ...
def quantized_concat_eager_fallback(concat_dim: Any, values: Any, input_mins: Any, input_maxes: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _QuantizedInstanceNormOutput = namedtuple('QuantizedInstanceNorm', <ERROR>)

def quantized_instance_norm(x: Any, x_min: Any, x_max: Any, output_range_given: bool = ..., given_y_min: int = ..., given_y_max: int = ..., variance_epsilon: float = ..., min_separation: float = ..., name: Optional[Any] = ...): ...
def quantized_instance_norm_eager_fallback(x: Any, x_min: Any, x_max: Any, output_range_given: bool = ..., given_y_min: int = ..., given_y_max: int = ..., variance_epsilon: float = ..., min_separation: float = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _QuantizedReshapeOutput = namedtuple('QuantizedReshape', <ERROR>)

def quantized_reshape(tensor: Any, shape: Any, input_min: Any, input_max: Any, name: Optional[Any] = ...): ...
def quantized_reshape_eager_fallback(tensor: Any, shape: Any, input_min: Any, input_max: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def rank(input: Any, name: Optional[Any] = ...): ...
def rank_eager_fallback(input: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def ref_identity(input: Any, name: Optional[Any] = ...): ...
def reshape(tensor: Any, shape: Any, name: Optional[Any] = ...): ...
def reshape_eager_fallback(tensor: Any, shape: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def resource_strided_slice_assign(ref: Any, begin: Any, end: Any, strides: Any, value: Any, begin_mask: int = ..., end_mask: int = ..., ellipsis_mask: int = ..., new_axis_mask: int = ..., shrink_axis_mask: int = ..., name: Optional[Any] = ...): ...
def resource_strided_slice_assign_eager_fallback(ref: Any, begin: Any, end: Any, strides: Any, value: Any, begin_mask: int = ..., end_mask: int = ..., ellipsis_mask: int = ..., new_axis_mask: int = ..., shrink_axis_mask: int = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def reverse(tensor: Any, dims: Any, name: Optional[Any] = ...): ...
def reverse_eager_fallback(tensor: Any, dims: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def reverse_sequence(input: Any, seq_lengths: Any, seq_dim: Any, batch_dim: int = ..., name: Optional[Any] = ...): ...
def reverse_sequence_eager_fallback(input: Any, seq_lengths: Any, seq_dim: Any, batch_dim: int = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def reverse_v2(tensor: Any, axis: Any, name: Optional[Any] = ...): ...
def reverse_v2_eager_fallback(tensor: Any, axis: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def scatter_nd(indices: Any, updates: Any, shape: Any, name: Optional[Any] = ...): ...
def scatter_nd_eager_fallback(indices: Any, updates: Any, shape: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def scatter_nd_non_aliasing_add(input: Any, indices: Any, updates: Any, name: Optional[Any] = ...): ...
def scatter_nd_non_aliasing_add_eager_fallback(input: Any, indices: Any, updates: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def shape(input: Any, out_type: Any = ..., name: Optional[Any] = ...): ...
def shape_eager_fallback(input: Any, out_type: Any = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def shape_n(input: Any, out_type: Any = ..., name: Optional[Any] = ...): ...
def shape_n_eager_fallback(input: Any, out_type: Any = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def size(input: Any, out_type: Any = ..., name: Optional[Any] = ...): ...
def size_eager_fallback(input: Any, out_type: Any = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def snapshot(input: Any, name: Optional[Any] = ...): ...
def snapshot_eager_fallback(input: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def space_to_batch(input: Any, paddings: Any, block_size: Any, name: Optional[Any] = ...): ...
def space_to_batch_eager_fallback(input: Any, paddings: Any, block_size: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def space_to_batch_nd(input: Any, block_shape: Any, paddings: Any, name: Optional[Any] = ...): ...
def space_to_batch_nd_eager_fallback(input: Any, block_shape: Any, paddings: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def space_to_depth(input: Any, block_size: Any, data_format: str = ..., name: Optional[Any] = ...): ...
def space_to_depth_eager_fallback(input: Any, block_size: Any, data_format: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def split(axis: Any, value: Any, num_split: Any, name: Optional[Any] = ...): ...
def split_eager_fallback(axis: Any, value: Any, num_split: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def split_v(value: Any, size_splits: Any, axis: Any, num_split: Any, name: Optional[Any] = ...): ...
def split_v_eager_fallback(value: Any, size_splits: Any, axis: Any, num_split: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def squeeze(input: Any, axis: Any = ..., name: Optional[Any] = ...): ...
def squeeze_eager_fallback(input: Any, axis: Any = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def stop_gradient(input: Any, name: Optional[Any] = ...): ...
def stop_gradient_eager_fallback(input: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def strided_slice(input: Any, begin: Any, end: Any, strides: Any, begin_mask: int = ..., end_mask: int = ..., ellipsis_mask: int = ..., new_axis_mask: int = ..., shrink_axis_mask: int = ..., name: Optional[Any] = ...): ...
def strided_slice_eager_fallback(input: Any, begin: Any, end: Any, strides: Any, begin_mask: int = ..., end_mask: int = ..., ellipsis_mask: int = ..., new_axis_mask: int = ..., shrink_axis_mask: int = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def strided_slice_assign(ref: Any, begin: Any, end: Any, strides: Any, value: Any, begin_mask: int = ..., end_mask: int = ..., ellipsis_mask: int = ..., new_axis_mask: int = ..., shrink_axis_mask: int = ..., name: Optional[Any] = ...): ...
def strided_slice_grad(shape: Any, begin: Any, end: Any, strides: Any, dy: Any, begin_mask: int = ..., end_mask: int = ..., ellipsis_mask: int = ..., new_axis_mask: int = ..., shrink_axis_mask: int = ..., name: Optional[Any] = ...): ...
def strided_slice_grad_eager_fallback(shape: Any, begin: Any, end: Any, strides: Any, dy: Any, begin_mask: int = ..., end_mask: int = ..., ellipsis_mask: int = ..., new_axis_mask: int = ..., shrink_axis_mask: int = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def tile(input: Any, multiples: Any, name: Optional[Any] = ...): ...
def tile_eager_fallback(input: Any, multiples: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def tile_grad(input: Any, multiples: Any, name: Optional[Any] = ...): ...
def tile_grad_eager_fallback(input: Any, multiples: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def transpose(x: Any, perm: Any, name: Optional[Any] = ...): ...
def transpose_eager_fallback(x: Any, perm: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _UniqueOutput = namedtuple('Unique', <ERROR>)

def unique(x: Any, out_idx: Any = ..., name: Optional[Any] = ...): ...
def unique_eager_fallback(x: Any, out_idx: Any = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _UniqueV2Output = namedtuple('UniqueV2', <ERROR>)

def unique_v2(x: Any, axis: Any, out_idx: Any = ..., name: Optional[Any] = ...): ...
def unique_v2_eager_fallback(x: Any, axis: Any, out_idx: Any = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _UniqueWithCountsOutput = namedtuple('UniqueWithCounts', <ERROR>)

def unique_with_counts(x: Any, out_idx: Any = ..., name: Optional[Any] = ...): ...
def unique_with_counts_eager_fallback(x: Any, out_idx: Any = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _UniqueWithCountsV2Output = namedtuple('UniqueWithCountsV2', <ERROR>)

def unique_with_counts_v2(x: Any, axis: Any, out_idx: Any = ..., name: Optional[Any] = ...): ...
def unique_with_counts_v2_eager_fallback(x: Any, axis: Any, out_idx: Any = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def unpack(value: Any, num: Any, axis: int = ..., name: Optional[Any] = ...): ...
def unpack_eager_fallback(value: Any, num: Any, axis: int = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def unravel_index(indices: Any, dims: Any, name: Optional[Any] = ...): ...
def unravel_index_eager_fallback(indices: Any, dims: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def upper_bound(sorted_inputs: Any, values: Any, out_type: Any = ..., name: Optional[Any] = ...): ...
def upper_bound_eager_fallback(sorted_inputs: Any, values: Any, out_type: Any = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def where(condition: Any, name: Optional[Any] = ...): ...
def where_eager_fallback(condition: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def zeros_like(x: Any, name: Optional[Any] = ...): ...
def zeros_like_eager_fallback(x: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
