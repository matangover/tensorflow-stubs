# Stubs for tensorflow.contrib.rnn.python.ops.rnn_cell (Python 3)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

from tensorflow.contrib.compiler import jit as jit
from tensorflow.contrib.layers.python.layers import layers as layers
from tensorflow.contrib.rnn.python.ops import core_rnn_cell as core_rnn_cell
from tensorflow.python.framework import constant_op as constant_op, dtypes as dtypes, op_def_registry as op_def_registry, ops as ops, tensor_shape as tensor_shape
from tensorflow.python.ops import array_ops as array_ops, clip_ops as clip_ops, gen_array_ops as gen_array_ops, init_ops as init_ops, math_ops as math_ops, nn_impl as nn_impl, nn_ops as nn_ops, partitioned_variables as partitioned_variables, random_ops as random_ops, rnn_cell_impl as rnn_cell_impl
from tensorflow.python.util import nest as nest
from typing import Any as Any, Optional as Optional

class CoupledInputForgetGateLSTMCell(rnn_cell_impl.RNNCell):
    def __init__(self, num_units: Any, use_peepholes: bool = ..., initializer: Optional[Any] = ..., num_proj: Optional[Any] = ..., proj_clip: Optional[Any] = ..., num_unit_shards: int = ..., num_proj_shards: int = ..., forget_bias: float = ..., state_is_tuple: bool = ..., activation: Any = ..., reuse: Optional[Any] = ..., layer_norm: bool = ..., norm_gain: float = ..., norm_shift: float = ...) -> None: ...
    @property
    def state_size(self): ...
    @property
    def output_size(self): ...
    def call(self, inputs: Any, state: Any): ...

class TimeFreqLSTMCell(rnn_cell_impl.RNNCell):
    def __init__(self, num_units: Any, use_peepholes: bool = ..., cell_clip: Optional[Any] = ..., initializer: Optional[Any] = ..., num_unit_shards: int = ..., forget_bias: float = ..., feature_size: Optional[Any] = ..., frequency_skip: int = ..., reuse: Optional[Any] = ...) -> None: ...
    @property
    def output_size(self): ...
    @property
    def state_size(self): ...
    def call(self, inputs: Any, state: Any): ...

class GridLSTMCell(rnn_cell_impl.RNNCell):
    def __init__(self, num_units: Any, use_peepholes: bool = ..., share_time_frequency_weights: bool = ..., cell_clip: Optional[Any] = ..., initializer: Optional[Any] = ..., num_unit_shards: int = ..., forget_bias: float = ..., feature_size: Optional[Any] = ..., frequency_skip: Optional[Any] = ..., num_frequency_blocks: Optional[Any] = ..., start_freqindex_list: Optional[Any] = ..., end_freqindex_list: Optional[Any] = ..., couple_input_forget_gates: bool = ..., state_is_tuple: bool = ..., reuse: Optional[Any] = ...) -> None: ...
    @property
    def output_size(self): ...
    @property
    def state_size(self): ...
    @property
    def state_tuple_type(self): ...
    def call(self, inputs: Any, state: Any): ...

class BidirectionalGridLSTMCell(GridLSTMCell):
    def __init__(self, num_units: Any, use_peepholes: bool = ..., share_time_frequency_weights: bool = ..., cell_clip: Optional[Any] = ..., initializer: Optional[Any] = ..., num_unit_shards: int = ..., forget_bias: float = ..., feature_size: Optional[Any] = ..., frequency_skip: Optional[Any] = ..., num_frequency_blocks: Optional[Any] = ..., start_freqindex_list: Optional[Any] = ..., end_freqindex_list: Optional[Any] = ..., couple_input_forget_gates: bool = ..., backward_slice_offset: int = ..., reuse: Optional[Any] = ...) -> None: ...
    def call(self, inputs: Any, state: Any): ...

class AttentionCellWrapper(rnn_cell_impl.RNNCell):
    def __init__(self, cell: Any, attn_length: Any, attn_size: Optional[Any] = ..., attn_vec_size: Optional[Any] = ..., input_size: Optional[Any] = ..., state_is_tuple: bool = ..., reuse: Optional[Any] = ...) -> None: ...
    @property
    def state_size(self): ...
    @property
    def output_size(self): ...
    def call(self, inputs: Any, state: Any): ...

class HighwayWrapper(rnn_cell_impl.RNNCell):
    def __init__(self, cell: Any, couple_carry_transform_gates: bool = ..., carry_bias_init: float = ...) -> None: ...
    @property
    def state_size(self): ...
    @property
    def output_size(self): ...
    def zero_state(self, batch_size: Any, dtype: Any): ...
    def __call__(self, inputs: Any, state: Any, scope: Optional[Any] = ...): ...

class LayerNormBasicLSTMCell(rnn_cell_impl.RNNCell):
    def __init__(self, num_units: Any, forget_bias: float = ..., input_size: Optional[Any] = ..., activation: Any = ..., layer_norm: bool = ..., norm_gain: float = ..., norm_shift: float = ..., dropout_keep_prob: float = ..., dropout_prob_seed: Optional[Any] = ..., reuse: Optional[Any] = ...) -> None: ...
    @property
    def state_size(self): ...
    @property
    def output_size(self): ...
    def call(self, inputs: Any, state: Any): ...

class NASCell(rnn_cell_impl.RNNCell):
    def __init__(self, num_units: Any, num_proj: Optional[Any] = ..., use_biases: bool = ..., reuse: Optional[Any] = ...) -> None: ...
    @property
    def state_size(self): ...
    @property
    def output_size(self): ...
    def call(self, inputs: Any, state: Any): ...

class UGRNNCell(rnn_cell_impl.RNNCell):
    def __init__(self, num_units: Any, initializer: Optional[Any] = ..., forget_bias: float = ..., activation: Any = ..., reuse: Optional[Any] = ...) -> None: ...
    @property
    def state_size(self): ...
    @property
    def output_size(self): ...
    def call(self, inputs: Any, state: Any): ...

class IntersectionRNNCell(rnn_cell_impl.RNNCell):
    def __init__(self, num_units: Any, num_in_proj: Optional[Any] = ..., initializer: Optional[Any] = ..., forget_bias: float = ..., y_activation: Any = ..., reuse: Optional[Any] = ...) -> None: ...
    @property
    def state_size(self): ...
    @property
    def output_size(self): ...
    def call(self, inputs: Any, state: Any): ...

class CompiledWrapper(rnn_cell_impl.RNNCell):
    def __init__(self, cell: Any, compile_stateful: bool = ...) -> None: ...
    @property
    def state_size(self): ...
    @property
    def output_size(self): ...
    def zero_state(self, batch_size: Any, dtype: Any): ...
    def __call__(self, inputs: Any, state: Any, scope: Optional[Any] = ...): ...

class PhasedLSTMCell(rnn_cell_impl.RNNCell):
    def __init__(self, num_units: Any, use_peepholes: bool = ..., leak: float = ..., ratio_on: float = ..., trainable_ratio_on: bool = ..., period_init_min: float = ..., period_init_max: float = ..., reuse: Optional[Any] = ...) -> None: ...
    @property
    def state_size(self): ...
    @property
    def output_size(self): ...
    def call(self, inputs: Any, state: Any): ...

class ConvLSTMCell(rnn_cell_impl.RNNCell):
    def __init__(self, conv_ndims: Any, input_shape: Any, output_channels: Any, kernel_shape: Any, use_bias: bool = ..., skip_connection: bool = ..., forget_bias: float = ..., initializers: Optional[Any] = ..., name: str = ...) -> None: ...
    @property
    def output_size(self): ...
    @property
    def state_size(self): ...
    def call(self, inputs: Any, state: Any, scope: Optional[Any] = ...): ...

class Conv1DLSTMCell(ConvLSTMCell):
    def __init__(self, name: str = ..., **kwargs: Any) -> None: ...

class Conv2DLSTMCell(ConvLSTMCell):
    def __init__(self, name: str = ..., **kwargs: Any) -> None: ...

class Conv3DLSTMCell(ConvLSTMCell):
    def __init__(self, name: str = ..., **kwargs: Any) -> None: ...

class GLSTMCell(rnn_cell_impl.RNNCell):
    def __init__(self, num_units: Any, initializer: Optional[Any] = ..., num_proj: Optional[Any] = ..., number_of_groups: int = ..., forget_bias: float = ..., activation: Any = ..., reuse: Optional[Any] = ...) -> None: ...
    @property
    def state_size(self): ...
    @property
    def output_size(self): ...
    def call(self, inputs: Any, state: Any): ...

class LayerNormLSTMCell(rnn_cell_impl.RNNCell):
    def __init__(self, num_units: Any, use_peepholes: bool = ..., cell_clip: Optional[Any] = ..., initializer: Optional[Any] = ..., num_proj: Optional[Any] = ..., proj_clip: Optional[Any] = ..., forget_bias: float = ..., activation: Optional[Any] = ..., layer_norm: bool = ..., norm_gain: float = ..., norm_shift: float = ..., reuse: Optional[Any] = ...) -> None: ...
    @property
    def state_size(self): ...
    @property
    def output_size(self): ...
    def call(self, inputs: Any, state: Any): ...

class SRUCell(rnn_cell_impl.LayerRNNCell):
    input_spec: Any = ...
    def __init__(self, num_units: Any, activation: Optional[Any] = ..., reuse: Optional[Any] = ..., name: Optional[Any] = ...) -> None: ...
    @property
    def state_size(self): ...
    @property
    def output_size(self): ...
    def build(self, inputs_shape: Any) -> None: ...
    def call(self, inputs: Any, state: Any): ...

class WeightNormLSTMCell(rnn_cell_impl.RNNCell):
    def __init__(self, num_units: Any, norm: bool = ..., use_peepholes: bool = ..., cell_clip: Optional[Any] = ..., initializer: Optional[Any] = ..., num_proj: Optional[Any] = ..., proj_clip: Optional[Any] = ..., forget_bias: int = ..., activation: Optional[Any] = ..., reuse: Optional[Any] = ...) -> None: ...
    @property
    def state_size(self): ...
    @property
    def output_size(self): ...
    def call(self, inputs: Any, state: Any): ...

class IndRNNCell(rnn_cell_impl.LayerRNNCell):
    input_spec: Any = ...
    def __init__(self, num_units: Any, activation: Optional[Any] = ..., reuse: Optional[Any] = ..., name: Optional[Any] = ..., dtype: Optional[Any] = ...) -> None: ...
    @property
    def state_size(self): ...
    @property
    def output_size(self): ...
    built: bool = ...
    def build(self, inputs_shape: Any) -> None: ...
    def call(self, inputs: Any, state: Any): ...

class IndyGRUCell(rnn_cell_impl.LayerRNNCell):
    input_spec: Any = ...
    def __init__(self, num_units: Any, activation: Optional[Any] = ..., reuse: Optional[Any] = ..., kernel_initializer: Optional[Any] = ..., bias_initializer: Optional[Any] = ..., name: Optional[Any] = ..., dtype: Optional[Any] = ...) -> None: ...
    @property
    def state_size(self): ...
    @property
    def output_size(self): ...
    built: bool = ...
    def build(self, inputs_shape: Any) -> None: ...
    def call(self, inputs: Any, state: Any): ...

class IndyLSTMCell(rnn_cell_impl.LayerRNNCell):
    input_spec: Any = ...
    def __init__(self, num_units: Any, forget_bias: float = ..., activation: Optional[Any] = ..., reuse: Optional[Any] = ..., kernel_initializer: Optional[Any] = ..., bias_initializer: Optional[Any] = ..., name: Optional[Any] = ..., dtype: Optional[Any] = ...) -> None: ...
    @property
    def state_size(self): ...
    @property
    def output_size(self): ...
    built: bool = ...
    def build(self, inputs_shape: Any) -> None: ...
    def call(self, inputs: Any, state: Any): ...
