# Stubs for tensorflow.contrib.tpu.ops.gen_tpu_ops (Python 3)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

from collections import namedtuple as namedtuple
from tensorflow.python.util.deprecation import deprecated_endpoints as deprecated_endpoints
from tensorflow.python.util.tf_export import tf_export as tf_export
from typing import Any as Any, Optional as Optional

def all_to_all(input: Any, group_assignment: Any, concat_dimension: Any, split_dimension: Any, split_count: Any, name: Optional[Any] = ...): ...
def all_to_all_eager_fallback(input: Any, group_assignment: Any, concat_dimension: Any, split_dimension: Any, split_count: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def collective_permute(input: Any, source_target_pairs: Any, name: Optional[Any] = ...): ...
def collective_permute_eager_fallback(input: Any, source_target_pairs: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def configure_distributed_tpu(embedding_config: str = ..., tpu_embedding_config: str = ..., is_global_init: bool = ..., name: Optional[Any] = ...): ...
def configure_distributed_tpu_eager_fallback(embedding_config: str = ..., tpu_embedding_config: str = ..., is_global_init: bool = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def cross_replica_sum(input: Any, group_assignment: Any, name: Optional[Any] = ...): ...
def cross_replica_sum_eager_fallback(input: Any, group_assignment: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def infeed_dequeue(dtype: Any, shape: Any, name: Optional[Any] = ...): ...
def infeed_dequeue_eager_fallback(dtype: Any, shape: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def infeed_dequeue_tuple(dtypes: Any, shapes: Any, name: Optional[Any] = ...): ...
def infeed_dequeue_tuple_eager_fallback(dtypes: Any, shapes: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def infeed_enqueue(input: Any, shape: Any = ..., device_ordinal: int = ..., name: Optional[Any] = ...): ...
def infeed_enqueue_eager_fallback(input: Any, shape: Any = ..., device_ordinal: int = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def infeed_enqueue_tuple(inputs: Any, shapes: Any, device_ordinal: int = ..., name: Optional[Any] = ...): ...
def infeed_enqueue_tuple_eager_fallback(inputs: Any, shapes: Any, device_ordinal: int = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def load_tpu_embedding_adam_parameters(parameters: Any, momenta: Any, velocities: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def load_tpu_embedding_adam_parameters_eager_fallback(parameters: Any, momenta: Any, velocities: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def load_tpu_embedding_adam_parameters_grad_accum_debug(parameters: Any, momenta: Any, velocities: Any, gradient_accumulators: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def load_tpu_embedding_adam_parameters_grad_accum_debug_eager_fallback(parameters: Any, momenta: Any, velocities: Any, gradient_accumulators: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def load_tpu_embedding_adadelta_parameters(parameters: Any, accumulators: Any, updates: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def load_tpu_embedding_adadelta_parameters_eager_fallback(parameters: Any, accumulators: Any, updates: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def load_tpu_embedding_adadelta_parameters_grad_accum_debug(parameters: Any, accumulators: Any, updates: Any, gradient_accumulators: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def load_tpu_embedding_adadelta_parameters_grad_accum_debug_eager_fallback(parameters: Any, accumulators: Any, updates: Any, gradient_accumulators: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def load_tpu_embedding_adagrad_parameters(parameters: Any, accumulators: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def load_tpu_embedding_adagrad_parameters_eager_fallback(parameters: Any, accumulators: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def load_tpu_embedding_adagrad_parameters_grad_accum_debug(parameters: Any, accumulators: Any, gradient_accumulators: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def load_tpu_embedding_adagrad_parameters_grad_accum_debug_eager_fallback(parameters: Any, accumulators: Any, gradient_accumulators: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def load_tpu_embedding_centered_rms_prop_parameters(parameters: Any, ms: Any, mom: Any, mg: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def load_tpu_embedding_centered_rms_prop_parameters_eager_fallback(parameters: Any, ms: Any, mom: Any, mg: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def load_tpu_embedding_ftrl_parameters(parameters: Any, accumulators: Any, linears: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def load_tpu_embedding_ftrl_parameters_eager_fallback(parameters: Any, accumulators: Any, linears: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def load_tpu_embedding_ftrl_parameters_grad_accum_debug(parameters: Any, accumulators: Any, linears: Any, gradient_accumulators: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def load_tpu_embedding_ftrl_parameters_grad_accum_debug_eager_fallback(parameters: Any, accumulators: Any, linears: Any, gradient_accumulators: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def load_tpu_embedding_mdl_adagrad_light_parameters(parameters: Any, accumulators: Any, weights: Any, benefits: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def load_tpu_embedding_mdl_adagrad_light_parameters_eager_fallback(parameters: Any, accumulators: Any, weights: Any, benefits: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def load_tpu_embedding_momentum_parameters(parameters: Any, momenta: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def load_tpu_embedding_momentum_parameters_eager_fallback(parameters: Any, momenta: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def load_tpu_embedding_momentum_parameters_grad_accum_debug(parameters: Any, momenta: Any, gradient_accumulators: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def load_tpu_embedding_momentum_parameters_grad_accum_debug_eager_fallback(parameters: Any, momenta: Any, gradient_accumulators: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def load_tpu_embedding_proximal_adagrad_parameters(parameters: Any, accumulators: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def load_tpu_embedding_proximal_adagrad_parameters_eager_fallback(parameters: Any, accumulators: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def load_tpu_embedding_proximal_adagrad_parameters_grad_accum_debug(parameters: Any, accumulators: Any, gradient_accumulators: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def load_tpu_embedding_proximal_adagrad_parameters_grad_accum_debug_eager_fallback(parameters: Any, accumulators: Any, gradient_accumulators: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def load_tpu_embedding_rms_prop_parameters(parameters: Any, ms: Any, mom: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def load_tpu_embedding_rms_prop_parameters_eager_fallback(parameters: Any, ms: Any, mom: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def load_tpu_embedding_rms_prop_parameters_grad_accum_debug(parameters: Any, ms: Any, mom: Any, gradient_accumulators: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def load_tpu_embedding_rms_prop_parameters_grad_accum_debug_eager_fallback(parameters: Any, ms: Any, mom: Any, gradient_accumulators: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def load_tpu_embedding_stochastic_gradient_descent_parameters(parameters: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def load_tpu_embedding_stochastic_gradient_descent_parameters_eager_fallback(parameters: Any, num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def outfeed_dequeue(dtype: Any, shape: Any, device_ordinal: int = ..., name: Optional[Any] = ...): ...
def outfeed_dequeue_eager_fallback(dtype: Any, shape: Any, device_ordinal: int = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def outfeed_dequeue_tuple(dtypes: Any, shapes: Any, device_ordinal: int = ..., name: Optional[Any] = ...): ...
def outfeed_dequeue_tuple_eager_fallback(dtypes: Any, shapes: Any, device_ordinal: int = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def outfeed_enqueue(input: Any, name: Optional[Any] = ...): ...
def outfeed_enqueue_eager_fallback(input: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def outfeed_enqueue_tuple(inputs: Any, name: Optional[Any] = ...): ...
def outfeed_enqueue_tuple_eager_fallback(inputs: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def recv_tpu_embedding_activations(num_outputs: Any, config: Any, name: Optional[Any] = ...): ...
def recv_tpu_embedding_activations_eager_fallback(num_outputs: Any, config: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _RetrieveTPUEmbeddingADAMParametersOutput = namedtuple('RetrieveTPUEmbeddingADAMParameters', <ERROR>)

def retrieve_tpu_embedding_adam_parameters(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def retrieve_tpu_embedding_adam_parameters_eager_fallback(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _RetrieveTPUEmbeddingADAMParametersGradAccumDebugOutput = namedtuple('RetrieveTPUEmbeddingADAMParametersGradAccumDebug', <ERROR>)

def retrieve_tpu_embedding_adam_parameters_grad_accum_debug(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def retrieve_tpu_embedding_adam_parameters_grad_accum_debug_eager_fallback(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _RetrieveTPUEmbeddingAdadeltaParametersOutput = namedtuple('RetrieveTPUEmbeddingAdadeltaParameters', <ERROR>)

def retrieve_tpu_embedding_adadelta_parameters(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def retrieve_tpu_embedding_adadelta_parameters_eager_fallback(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _RetrieveTPUEmbeddingAdadeltaParametersGradAccumDebugOutput = namedtuple('RetrieveTPUEmbeddingAdadeltaParametersGradAccumDebug', <ERROR>)

def retrieve_tpu_embedding_adadelta_parameters_grad_accum_debug(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def retrieve_tpu_embedding_adadelta_parameters_grad_accum_debug_eager_fallback(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _RetrieveTPUEmbeddingAdagradParametersOutput = namedtuple('RetrieveTPUEmbeddingAdagradParameters', <ERROR>)

def retrieve_tpu_embedding_adagrad_parameters(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def retrieve_tpu_embedding_adagrad_parameters_eager_fallback(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _RetrieveTPUEmbeddingAdagradParametersGradAccumDebugOutput = namedtuple('RetrieveTPUEmbeddingAdagradParametersGradAccumDebug', <ERROR>)

def retrieve_tpu_embedding_adagrad_parameters_grad_accum_debug(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def retrieve_tpu_embedding_adagrad_parameters_grad_accum_debug_eager_fallback(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _RetrieveTPUEmbeddingCenteredRMSPropParametersOutput = namedtuple('RetrieveTPUEmbeddingCenteredRMSPropParameters', <ERROR>)

def retrieve_tpu_embedding_centered_rms_prop_parameters(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def retrieve_tpu_embedding_centered_rms_prop_parameters_eager_fallback(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _RetrieveTPUEmbeddingFTRLParametersOutput = namedtuple('RetrieveTPUEmbeddingFTRLParameters', <ERROR>)

def retrieve_tpu_embedding_ftrl_parameters(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def retrieve_tpu_embedding_ftrl_parameters_eager_fallback(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _RetrieveTPUEmbeddingFTRLParametersGradAccumDebugOutput = namedtuple('RetrieveTPUEmbeddingFTRLParametersGradAccumDebug', <ERROR>)

def retrieve_tpu_embedding_ftrl_parameters_grad_accum_debug(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def retrieve_tpu_embedding_ftrl_parameters_grad_accum_debug_eager_fallback(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _RetrieveTPUEmbeddingMDLAdagradLightParametersOutput = namedtuple('RetrieveTPUEmbeddingMDLAdagradLightParameters', <ERROR>)

def retrieve_tpu_embedding_mdl_adagrad_light_parameters(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def retrieve_tpu_embedding_mdl_adagrad_light_parameters_eager_fallback(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _RetrieveTPUEmbeddingMomentumParametersOutput = namedtuple('RetrieveTPUEmbeddingMomentumParameters', <ERROR>)

def retrieve_tpu_embedding_momentum_parameters(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def retrieve_tpu_embedding_momentum_parameters_eager_fallback(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _RetrieveTPUEmbeddingMomentumParametersGradAccumDebugOutput = namedtuple('RetrieveTPUEmbeddingMomentumParametersGradAccumDebug', <ERROR>)

def retrieve_tpu_embedding_momentum_parameters_grad_accum_debug(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def retrieve_tpu_embedding_momentum_parameters_grad_accum_debug_eager_fallback(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _RetrieveTPUEmbeddingProximalAdagradParametersOutput = namedtuple('RetrieveTPUEmbeddingProximalAdagradParameters', <ERROR>)

def retrieve_tpu_embedding_proximal_adagrad_parameters(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def retrieve_tpu_embedding_proximal_adagrad_parameters_eager_fallback(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _RetrieveTPUEmbeddingProximalAdagradParametersGradAccumDebugOutput = namedtuple('RetrieveTPUEmbeddingProximalAdagradParametersGradAccumDebug', <ERROR>)

def retrieve_tpu_embedding_proximal_adagrad_parameters_grad_accum_debug(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def retrieve_tpu_embedding_proximal_adagrad_parameters_grad_accum_debug_eager_fallback(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _RetrieveTPUEmbeddingRMSPropParametersOutput = namedtuple('RetrieveTPUEmbeddingRMSPropParameters', <ERROR>)

def retrieve_tpu_embedding_rms_prop_parameters(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def retrieve_tpu_embedding_rms_prop_parameters_eager_fallback(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _RetrieveTPUEmbeddingRMSPropParametersGradAccumDebugOutput = namedtuple('RetrieveTPUEmbeddingRMSPropParametersGradAccumDebug', <ERROR>)

def retrieve_tpu_embedding_rms_prop_parameters_grad_accum_debug(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def retrieve_tpu_embedding_rms_prop_parameters_grad_accum_debug_eager_fallback(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def retrieve_tpu_embedding_stochastic_gradient_descent_parameters(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ...): ...
def retrieve_tpu_embedding_stochastic_gradient_descent_parameters_eager_fallback(num_shards: Any, shard_id: Any, table_id: int = ..., table_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def shutdown_distributed_tpu(name: Optional[Any] = ...): ...
def shutdown_distributed_tpu_eager_fallback(name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def tpu_compilation_result(name: Optional[Any] = ...): ...
def tpu_compilation_result_eager_fallback(name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def tpu_embedding_activations(embedding_variable: Any, sliced_activations: Any, table_id: Any, lookup_id: Any, name: Optional[Any] = ...): ...
def tpu_embedding_activations_eager_fallback(embedding_variable: Any, sliced_activations: Any, table_id: Any, lookup_id: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def tpu_replicate(inputs: Any, broadcast_inputs: Any, variables: Any, guaranteed_constants: Any, computation: Any, num_replicas: Any, output_types: Any, num_cores_per_replica: int = ..., topology: str = ..., use_tpu: bool = ..., device_assignment: Any = ..., host_compute_core: Any = ..., name: Optional[Any] = ...): ...
def tpu_replicate_eager_fallback(inputs: Any, broadcast_inputs: Any, variables: Any, guaranteed_constants: Any, computation: Any, num_replicas: Any, output_types: Any, num_cores_per_replica: int = ..., topology: str = ..., use_tpu: bool = ..., device_assignment: Any = ..., host_compute_core: Any = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def tpu_replicate_metadata(num_replicas: Any, num_cores_per_replica: int = ..., topology: str = ..., use_tpu: bool = ..., device_assignment: Any = ..., computation_shape: Any = ..., host_compute_core: Any = ..., name: Optional[Any] = ...): ...
def tpu_replicate_metadata_eager_fallback(num_replicas: Any, num_cores_per_replica: int = ..., topology: str = ..., use_tpu: bool = ..., device_assignment: Any = ..., computation_shape: Any = ..., host_compute_core: Any = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def tpu_replicated_input(inputs: Any, name: Optional[Any] = ...): ...
def tpu_replicated_input_eager_fallback(inputs: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def tpu_replicated_output(input: Any, num_replicas: Any, name: Optional[Any] = ...): ...
def tpu_replicated_output_eager_fallback(input: Any, num_replicas: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def worker_heartbeat(request: Any, name: Optional[Any] = ...): ...
def worker_heartbeat_eager_fallback(request: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
