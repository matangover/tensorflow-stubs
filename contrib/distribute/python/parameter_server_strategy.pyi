# Stubs for tensorflow.contrib.distribute.python.parameter_server_strategy (Python 3)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

from tensorflow.contrib.distribute.python import mirrored_strategy as mirrored_strategy, values as values
from tensorflow.python.distribute import multi_worker_util as multi_worker_util
from tensorflow.python.eager import context as context
from tensorflow.python.framework import ops as ops
from tensorflow.python.ops import array_ops as array_ops, resource_variable_ops as resource_variable_ops
from tensorflow.python.training import device_setter as device_setter, device_util as device_util, distribute as distribute_lib
from tensorflow.python.util import nest as nest
from typing import Any as Any, Optional as Optional

class ParameterServerStrategy(distribute_lib.DistributionStrategy):
    def __init__(self, num_gpus_per_worker: int = ...) -> None: ...
    def distribute_dataset(self, dataset_fn: Any): ...
    def value_container(self, val: Any): ...
    def read_var(self, var: Any): ...
    def configure(self, session_config: Optional[Any] = ..., cluster_spec: Optional[Any] = ..., task_type: Optional[Any] = ..., task_id: Optional[Any] = ...) -> None: ...
    @property
    def num_towers(self): ...
    @property
    def worker_devices(self): ...
    @property
    def parameter_devices(self): ...
    def non_slot_devices(self, var_list: Any): ...
    @property
    def between_graph(self): ...
    @property
    def should_init(self): ...
    @property
    def should_checkpoint(self): ...
    @property
    def should_save_summary(self): ...
