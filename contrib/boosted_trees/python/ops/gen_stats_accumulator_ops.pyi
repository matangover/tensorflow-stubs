# Stubs for tensorflow.contrib.boosted_trees.python.ops.gen_stats_accumulator_ops (Python 3)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

from collections import namedtuple as namedtuple
from tensorflow.python.util.deprecation import deprecated_endpoints as deprecated_endpoints
from tensorflow.python.util.tf_export import tf_export as tf_export
from typing import Any as Any, Optional as Optional

def create_stats_accumulator_scalar(stats_accumulator_handle: Any, stamp_token: Any, name: Optional[Any] = ...): ...
def create_stats_accumulator_scalar_eager_fallback(stats_accumulator_handle: Any, stamp_token: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def create_stats_accumulator_tensor(stats_accumulator_handle: Any, stamp_token: Any, per_slot_gradient_shape: Any, per_slot_hessian_shape: Any, name: Optional[Any] = ...): ...
def create_stats_accumulator_tensor_eager_fallback(stats_accumulator_handle: Any, stamp_token: Any, per_slot_gradient_shape: Any, per_slot_hessian_shape: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def stats_accumulator_scalar_add(stats_accumulator_handles: Any, stamp_token: Any, partition_ids: Any, feature_ids: Any, gradients: Any, hessians: Any, name: Optional[Any] = ...): ...
def stats_accumulator_scalar_add_eager_fallback(stats_accumulator_handles: Any, stamp_token: Any, partition_ids: Any, feature_ids: Any, gradients: Any, hessians: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def stats_accumulator_scalar_deserialize(stats_accumulator_handle: Any, stamp_token: Any, num_updates: Any, partition_ids: Any, feature_ids: Any, gradients: Any, hessians: Any, name: Optional[Any] = ...): ...
def stats_accumulator_scalar_deserialize_eager_fallback(stats_accumulator_handle: Any, stamp_token: Any, num_updates: Any, partition_ids: Any, feature_ids: Any, gradients: Any, hessians: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _StatsAccumulatorScalarFlushOutput = namedtuple('StatsAccumulatorScalarFlush', <ERROR>)

def stats_accumulator_scalar_flush(stats_accumulator_handle: Any, stamp_token: Any, next_stamp_token: Any, name: Optional[Any] = ...): ...
def stats_accumulator_scalar_flush_eager_fallback(stats_accumulator_handle: Any, stamp_token: Any, next_stamp_token: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def stats_accumulator_scalar_is_initialized(stats_accumulator_handle: Any, name: Optional[Any] = ...): ...
def stats_accumulator_scalar_is_initialized_eager_fallback(stats_accumulator_handle: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _StatsAccumulatorScalarMakeSummaryOutput = namedtuple('StatsAccumulatorScalarMakeSummary', <ERROR>)

def stats_accumulator_scalar_make_summary(partition_ids: Any, feature_ids: Any, gradients: Any, hessians: Any, name: Optional[Any] = ...): ...
def stats_accumulator_scalar_make_summary_eager_fallback(partition_ids: Any, feature_ids: Any, gradients: Any, hessians: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def stats_accumulator_scalar_resource_handle_op(container: str = ..., shared_name: str = ..., name: Optional[Any] = ...): ...
def stats_accumulator_scalar_resource_handle_op_eager_fallback(container: str = ..., shared_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _StatsAccumulatorScalarSerializeOutput = namedtuple('StatsAccumulatorScalarSerialize', <ERROR>)

def stats_accumulator_scalar_serialize(stats_accumulator_handle: Any, name: Optional[Any] = ...): ...
def stats_accumulator_scalar_serialize_eager_fallback(stats_accumulator_handle: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def stats_accumulator_tensor_add(stats_accumulator_handles: Any, stamp_token: Any, partition_ids: Any, feature_ids: Any, gradients: Any, hessians: Any, name: Optional[Any] = ...): ...
def stats_accumulator_tensor_add_eager_fallback(stats_accumulator_handles: Any, stamp_token: Any, partition_ids: Any, feature_ids: Any, gradients: Any, hessians: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def stats_accumulator_tensor_deserialize(stats_accumulator_handle: Any, stamp_token: Any, num_updates: Any, partition_ids: Any, feature_ids: Any, gradients: Any, hessians: Any, name: Optional[Any] = ...): ...
def stats_accumulator_tensor_deserialize_eager_fallback(stats_accumulator_handle: Any, stamp_token: Any, num_updates: Any, partition_ids: Any, feature_ids: Any, gradients: Any, hessians: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _StatsAccumulatorTensorFlushOutput = namedtuple('StatsAccumulatorTensorFlush', <ERROR>)

def stats_accumulator_tensor_flush(stats_accumulator_handle: Any, stamp_token: Any, next_stamp_token: Any, name: Optional[Any] = ...): ...
def stats_accumulator_tensor_flush_eager_fallback(stats_accumulator_handle: Any, stamp_token: Any, next_stamp_token: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def stats_accumulator_tensor_is_initialized(stats_accumulator_handle: Any, name: Optional[Any] = ...): ...
def stats_accumulator_tensor_is_initialized_eager_fallback(stats_accumulator_handle: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _StatsAccumulatorTensorMakeSummaryOutput = namedtuple('StatsAccumulatorTensorMakeSummary', <ERROR>)

def stats_accumulator_tensor_make_summary(partition_ids: Any, feature_ids: Any, gradients: Any, hessians: Any, name: Optional[Any] = ...): ...
def stats_accumulator_tensor_make_summary_eager_fallback(partition_ids: Any, feature_ids: Any, gradients: Any, hessians: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
def stats_accumulator_tensor_resource_handle_op(container: str = ..., shared_name: str = ..., name: Optional[Any] = ...): ...
def stats_accumulator_tensor_resource_handle_op_eager_fallback(container: str = ..., shared_name: str = ..., name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...

# _StatsAccumulatorTensorSerializeOutput = namedtuple('StatsAccumulatorTensorSerialize', <ERROR>)

def stats_accumulator_tensor_serialize(stats_accumulator_handle: Any, name: Optional[Any] = ...): ...
def stats_accumulator_tensor_serialize_eager_fallback(stats_accumulator_handle: Any, name: Optional[Any] = ..., ctx: Optional[Any] = ...): ...
